### RDD创建方式与value转换

首先RDD是什么：（英文直译：弹性分布数据集）

​	它是代码中的一个抽象类，它是将数据传输中的容器（数据类型以及具有的方法）抽象为一个类，当数据开始传输之后就有了RDD对象，使用者可以根据RDD提供的方法对里面的数据进行改变。

1. RDD里面的元素可以并行计算

    因为RDD里面的元素可以根据内核数量进行分区，每个分区对应一个核心，这样就可以并行操作，因此RDD就是Spark计算的最小单位

2. RDD里面具有切片的效果

    RDD根据有多少个核心，加上里面的分区规则，一般来说可以对内部元素进行合理的范围分区

3. RDD之间可以具有依赖关系

    RDD之间有可能有先后的生产关系，所以当上一个RDD没有生产时下一个RDD是依赖于上一个的

4. 存储kv的RDD还可以有可选的分区器

    只有kv的RDD才能够进行可选分区

5. RDD进行计算是，可以优先使用移动计算原则

    如果数据就在某个机器且资源充足的情况下，计算过程将在本机进行，如果资源不足，需要网络传输后进行计算

所以通过上面的描述，可以得知RDD是一个分布式存储的元素集合，RDD的数据都是只读数据，RDD的转换意味着要产生一个新的RDD模型，不会对原来的RDD产生任何影响，每个RDD可有多个分区，每个分区可能在不同的机器上进行计算

可以理解为RDD实际上就是将要计算的数据结合进行包装，并且可以根据这个集合进行分区，由于分区数量会和cpu核心数量保持一致，并且可以根据分区所在位置就进分配计算任务，所以RDD适用于分布式多核心分布并行计算的集群模式

所以RDD有以下特点

1. 弹性：

    存储弹性，容错弹性，计算弹性，分片弹性

2. 分区

3. 只读

4. 依赖（血缘）

5. 缓存

6. checkpoint（设置检查点，相当于游戏存档，方便从存档中读取数据，无需关系存档之前的游戏进度）

所以在spark编程中，就可以不用使用单一的map和reduce进行数据的计算，采用更加方便的spark算子传入相应的方法，对内部数据进行分散聚合操作，并且可以高效的在分布式集群当中并行计算，如果计算路线过长还可以对途中的RDD进行存档，后续的计算可以建立在存档之上。